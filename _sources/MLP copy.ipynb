{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssilvera/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle  # For saving and loading the model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, make_scorer\n",
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import os\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import optuna\n",
    "import joblib\n",
    "import time\n",
    "import numpy as np\n",
    "pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../Preprocessed data.xlsx\")\n",
    "#df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-08 13:15:09.296975: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-08 13:15:09.307461: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1739038509.322330  740841 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1739038509.324907  740841 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-08 13:15:09.333976: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[I 2025-02-08 13:15:10,404] A new study created in memory with name: no-name-57d6a2c7-281e-426b-b5f6-4e6515666cf3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study not found. Creating a new one...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
      "W0000 00:00:1739038510.454449  740841 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:16:07,395] Trial 0 finished with value: 0.8338268088898635 and parameters: {'n_layers': 2, 'units': 87, 'dropout_rate': 0.054033111531859544, 'learning_rate': 1.2701170001545189e-05}. Best is trial 0 with value: 0.8338268088898635.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:16:15,778] Trial 1 finished with value: 0.8549409312770501 and parameters: {'n_layers': 1, 'units': 219, 'dropout_rate': 0.28658549372927616, 'learning_rate': 0.0016958404576220476}. Best is trial 1 with value: 0.8549409312770501.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:16:29,181] Trial 2 finished with value: 0.8459517645256829 and parameters: {'n_layers': 3, 'units': 248, 'dropout_rate': 0.3228199582340264, 'learning_rate': 0.0036430144271463226}. Best is trial 1 with value: 0.8549409312770501.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:17:21,993] Trial 3 finished with value: 0.8561291898028492 and parameters: {'n_layers': 1, 'units': 254, 'dropout_rate': 0.057423575893141995, 'learning_rate': 6.292553889232716e-05}. Best is trial 3 with value: 0.8561291898028492.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:17:38,278] Trial 4 finished with value: 0.8561434666386234 and parameters: {'n_layers': 1, 'units': 209, 'dropout_rate': 0.40474344009828966, 'learning_rate': 0.00029346708674583377}. Best is trial 4 with value: 0.8561434666386234.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:17:43,845] Trial 5 finished with value: 0.8076728736882212 and parameters: {'n_layers': 1, 'units': 121, 'dropout_rate': 0.48236089200850885, 'learning_rate': 0.026537855314317006}. Best is trial 4 with value: 0.8561434666386234.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:18:14,179] Trial 6 finished with value: 0.8532317747385407 and parameters: {'n_layers': 1, 'units': 224, 'dropout_rate': 0.48253996986301917, 'learning_rate': 0.00018745313023394767}. Best is trial 4 with value: 0.8561434666386234.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:19:15,802] Trial 7 finished with value: 0.8585784441999732 and parameters: {'n_layers': 3, 'units': 237, 'dropout_rate': 0.46335009555914025, 'learning_rate': 8.697489751293547e-05}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:19:45,523] Trial 8 finished with value: 0.8562967846329963 and parameters: {'n_layers': 3, 'units': 116, 'dropout_rate': 0.39393779758937814, 'learning_rate': 0.0002627719764571511}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:20:16,412] Trial 9 finished with value: 0.8563348421875879 and parameters: {'n_layers': 2, 'units': 131, 'dropout_rate': 0.2587344666659917, 'learning_rate': 0.00015026342437474594}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:21:11,327] Trial 10 finished with value: 0.7874020184619549 and parameters: {'n_layers': 3, 'units': 35, 'dropout_rate': 0.22296981171248653, 'learning_rate': 1.0367872378199806e-05}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:22:03,286] Trial 11 finished with value: 0.8572607595830206 and parameters: {'n_layers': 2, 'units': 176, 'dropout_rate': 0.18863701896134957, 'learning_rate': 5.608423519534388e-05}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:23:04,098] Trial 12 finished with value: 0.8524459007845621 and parameters: {'n_layers': 2, 'units': 171, 'dropout_rate': 0.17699517583980673, 'learning_rate': 4.580574287484026e-05}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:24:09,267] Trial 13 finished with value: 0.8536175187207372 and parameters: {'n_layers': 3, 'units': 166, 'dropout_rate': 0.14766268806315505, 'learning_rate': 3.723283986507148e-05}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:24:24,010] Trial 14 finished with value: 0.8569559622192189 and parameters: {'n_layers': 2, 'units': 184, 'dropout_rate': 0.14993314989674156, 'learning_rate': 0.0009743092192580252}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:24:39,918] Trial 15 finished with value: 0.5422148689470829 and parameters: {'n_layers': 2, 'units': 195, 'dropout_rate': 0.3547494449918924, 'learning_rate': 0.06106791824761527}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:24:51,638] Trial 16 finished with value: 0.8544268563016727 and parameters: {'n_layers': 3, 'units': 156, 'dropout_rate': 0.20735946490731805, 'learning_rate': 0.0008009408026116916}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:25:00,392] Trial 17 finished with value: 0.8508804467000544 and parameters: {'n_layers': 2, 'units': 231, 'dropout_rate': 0.11713848510319608, 'learning_rate': 0.005457181001104522}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:25:55,712] Trial 18 finished with value: 0.8220400637174048 and parameters: {'n_layers': 3, 'units': 74, 'dropout_rate': 0.43362934561074906, 'learning_rate': 2.710755614845536e-05}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:26:37,237] Trial 19 finished with value: 0.8560498131426889 and parameters: {'n_layers': 2, 'units': 194, 'dropout_rate': 0.29825739464649603, 'learning_rate': 0.00010235795736939392}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:26:55,210] Trial 20 finished with value: 0.8568401298055501 and parameters: {'n_layers': 3, 'units': 145, 'dropout_rate': 0.23755490798343043, 'learning_rate': 0.0004280491955298675}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:27:07,740] Trial 21 finished with value: 0.8542462062715616 and parameters: {'n_layers': 2, 'units': 189, 'dropout_rate': 0.1224444761547332, 'learning_rate': 0.0013184969191867078}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:27:18,768] Trial 22 finished with value: 0.8225300302868152 and parameters: {'n_layers': 2, 'units': 176, 'dropout_rate': 0.1829012571676191, 'learning_rate': 0.009731564127875805}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:27:27,471] Trial 23 finished with value: 0.8492836070586185 and parameters: {'n_layers': 2, 'units': 235, 'dropout_rate': 0.09508409866712901, 'learning_rate': 0.000605880691650854}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:28:23,404] Trial 24 finished with value: 0.8563620958371617 and parameters: {'n_layers': 2, 'units': 206, 'dropout_rate': 0.17340033090764634, 'learning_rate': 7.570275507068332e-05}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:29:29,696] Trial 25 finished with value: 0.8400356598454607 and parameters: {'n_layers': 2, 'units': 186, 'dropout_rate': 0.34069100263989266, 'learning_rate': 2.0421721932253327e-05}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:30:00,668] Trial 26 finished with value: 0.8538309846488343 and parameters: {'n_layers': 3, 'units': 150, 'dropout_rate': 0.2500205548033312, 'learning_rate': 0.00014689728061114985}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:30:09,159] Trial 27 finished with value: 0.8543216448435483 and parameters: {'n_layers': 2, 'units': 98, 'dropout_rate': 0.14078571898165296, 'learning_rate': 0.0022320022099272282}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:30:18,793] Trial 28 finished with value: 0.8400958627915593 and parameters: {'n_layers': 2, 'units': 216, 'dropout_rate': 0.09357654627101142, 'learning_rate': 0.008926892077366336}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:31:20,623] Trial 29 finished with value: 0.8524094860303857 and parameters: {'n_layers': 3, 'units': 241, 'dropout_rate': 0.061600253129326876, 'learning_rate': 1.8080841938458594e-05}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:31:34,519] Trial 30 finished with value: 0.8533074178632508 and parameters: {'n_layers': 1, 'units': 161, 'dropout_rate': 0.19389151466556398, 'learning_rate': 0.00046794689948554687}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:31:50,468] Trial 31 finished with value: 0.8582514790145372 and parameters: {'n_layers': 3, 'units': 139, 'dropout_rate': 0.21772981700162652, 'learning_rate': 0.0003463856465306031}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:32:00,504] Trial 32 finished with value: 0.8545872099040719 and parameters: {'n_layers': 3, 'units': 126, 'dropout_rate': 0.16061847326964185, 'learning_rate': 0.001079603171311197}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:32:41,865] Trial 33 finished with value: 0.8551757814550679 and parameters: {'n_layers': 3, 'units': 137, 'dropout_rate': 0.27297766548039093, 'learning_rate': 0.00010708348606024476}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:32:54,079] Trial 34 finished with value: 0.8510820538087979 and parameters: {'n_layers': 2, 'units': 110, 'dropout_rate': 0.22468185516394634, 'learning_rate': 0.0023840302377438017}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:33:14,582] Trial 35 finished with value: 0.8563191877285314 and parameters: {'n_layers': 3, 'units': 180, 'dropout_rate': 0.30016023572534417, 'learning_rate': 0.00029289770414081355}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:34:16,635] Trial 36 finished with value: 0.8565362303545082 and parameters: {'n_layers': 2, 'units': 74, 'dropout_rate': 0.2065146746026167, 'learning_rate': 6.840341005861014e-05}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:35:21,718] Trial 37 finished with value: 0.8515781078543517 and parameters: {'n_layers': 1, 'units': 205, 'dropout_rate': 0.1293790892080454, 'learning_rate': 4.716615239071891e-05}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:35:55,705] Trial 38 finished with value: 0.8526290341992131 and parameters: {'n_layers': 3, 'units': 248, 'dropout_rate': 0.45244727276785346, 'learning_rate': 0.0002352696446019366}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:36:17,230] Trial 39 finished with value: 0.8544631973228638 and parameters: {'n_layers': 2, 'units': 222, 'dropout_rate': 0.37798291742120266, 'learning_rate': 0.00045619382723598205}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:36:55,777] Trial 40 finished with value: 0.8513449630090822 and parameters: {'n_layers': 1, 'units': 149, 'dropout_rate': 0.31919979697874706, 'learning_rate': 0.00011127262640406627}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:37:19,806] Trial 41 finished with value: 0.8585675194990291 and parameters: {'n_layers': 3, 'units': 102, 'dropout_rate': 0.24199588612812395, 'learning_rate': 0.0004050520046125325}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:37:39,415] Trial 42 finished with value: 0.8569435407346053 and parameters: {'n_layers': 3, 'units': 104, 'dropout_rate': 0.25209353452816163, 'learning_rate': 0.0006904091330180017}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:38:13,756] Trial 43 finished with value: 0.8540743211386354 and parameters: {'n_layers': 3, 'units': 82, 'dropout_rate': 0.2160036783317415, 'learning_rate': 0.000203795011330694}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:38:38,230] Trial 44 finished with value: 0.8545994499571331 and parameters: {'n_layers': 3, 'units': 135, 'dropout_rate': 0.27699507525918826, 'learning_rate': 0.0003110223088488059}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:38:55,249] Trial 45 finished with value: 0.8556203224446021 and parameters: {'n_layers': 3, 'units': 52, 'dropout_rate': 0.15550174816339263, 'learning_rate': 0.0013511520802264132}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:39:04,950] Trial 46 finished with value: 0.8438783367119493 and parameters: {'n_layers': 3, 'units': 92, 'dropout_rate': 0.18961232995010055, 'learning_rate': 0.0039245022810889384}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:40:24,631] Trial 47 finished with value: 0.851451570403285 and parameters: {'n_layers': 3, 'units': 115, 'dropout_rate': 0.2335476739088962, 'learning_rate': 3.596123689034504e-05}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:41:12,891] Trial 48 finished with value: 0.8563993021952259 and parameters: {'n_layers': 2, 'units': 170, 'dropout_rate': 0.4897163669048524, 'learning_rate': 0.00016885891366260215}. Best is trial 7 with value: 0.8585784441999732.\n",
      "/tmp/ipykernel_740841/1076475844.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:42:03,355] Trial 49 finished with value: 0.857356247237514 and parameters: {'n_layers': 3, 'units': 124, 'dropout_rate': 0.167015587577238, 'learning_rate': 6.492147332863847e-05}. Best is trial 7 with value: 0.8585784441999732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study saved as ../Study/optuna_study_MLP_2.pkl\n",
      "Best trial:\n",
      "  Value: 0.8585784441999732\n",
      "  Params: {'n_layers': 3, 'units': 237, 'dropout_rate': 0.46335009555914025, 'learning_rate': 8.697489751293547e-05}\n",
      "Optimization time: 1612.95 seconds\n",
      "Epoch 1/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5813 - loss: 1.1591 - val_accuracy: 0.7573 - val_loss: 0.6522\n",
      "Epoch 2/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6974 - loss: 0.7535 - val_accuracy: 0.7720 - val_loss: 0.5913\n",
      "Epoch 3/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7293 - loss: 0.6610 - val_accuracy: 0.7850 - val_loss: 0.5733\n",
      "Epoch 4/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7485 - loss: 0.6180 - val_accuracy: 0.7921 - val_loss: 0.5524\n",
      "Epoch 5/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7670 - loss: 0.5794 - val_accuracy: 0.7948 - val_loss: 0.5332\n",
      "Epoch 6/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7696 - loss: 0.5698 - val_accuracy: 0.7984 - val_loss: 0.5245\n",
      "Epoch 7/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7734 - loss: 0.5582 - val_accuracy: 0.8022 - val_loss: 0.5163\n",
      "Epoch 8/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7813 - loss: 0.5413 - val_accuracy: 0.8066 - val_loss: 0.5029\n",
      "Epoch 9/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7873 - loss: 0.5367 - val_accuracy: 0.8108 - val_loss: 0.5014\n",
      "Epoch 10/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7853 - loss: 0.5326 - val_accuracy: 0.8131 - val_loss: 0.4853\n",
      "Epoch 11/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7970 - loss: 0.5166 - val_accuracy: 0.8181 - val_loss: 0.4752\n",
      "Epoch 12/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8027 - loss: 0.4970 - val_accuracy: 0.8234 - val_loss: 0.4695\n",
      "Epoch 13/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8077 - loss: 0.4892 - val_accuracy: 0.8253 - val_loss: 0.4636\n",
      "Epoch 14/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8079 - loss: 0.4838 - val_accuracy: 0.8280 - val_loss: 0.4553\n",
      "Epoch 15/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8171 - loss: 0.4671 - val_accuracy: 0.8320 - val_loss: 0.4536\n",
      "Epoch 16/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8186 - loss: 0.4681 - val_accuracy: 0.8336 - val_loss: 0.4442\n",
      "Epoch 17/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8259 - loss: 0.4578 - val_accuracy: 0.8370 - val_loss: 0.4403\n",
      "Epoch 18/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8223 - loss: 0.4572 - val_accuracy: 0.8395 - val_loss: 0.4317\n",
      "Epoch 19/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8265 - loss: 0.4473 - val_accuracy: 0.8393 - val_loss: 0.4279\n",
      "Epoch 20/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.4441 - val_accuracy: 0.8429 - val_loss: 0.4224\n",
      "Epoch 21/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8286 - loss: 0.4520 - val_accuracy: 0.8433 - val_loss: 0.4174\n",
      "Epoch 22/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8351 - loss: 0.4364 - val_accuracy: 0.8422 - val_loss: 0.4164\n",
      "Epoch 23/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8383 - loss: 0.4246 - val_accuracy: 0.8477 - val_loss: 0.4128\n",
      "Epoch 24/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8368 - loss: 0.4261 - val_accuracy: 0.8483 - val_loss: 0.4105\n",
      "Epoch 25/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8421 - loss: 0.4184 - val_accuracy: 0.8494 - val_loss: 0.4065\n",
      "Epoch 26/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8444 - loss: 0.4161 - val_accuracy: 0.8496 - val_loss: 0.4036\n",
      "Epoch 27/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8401 - loss: 0.4241 - val_accuracy: 0.8464 - val_loss: 0.4034\n",
      "Epoch 28/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8463 - loss: 0.4070 - val_accuracy: 0.8532 - val_loss: 0.4025\n",
      "Epoch 29/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8497 - loss: 0.4032 - val_accuracy: 0.8508 - val_loss: 0.3976\n",
      "Epoch 30/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8508 - loss: 0.4023 - val_accuracy: 0.8517 - val_loss: 0.3970\n",
      "Epoch 31/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8470 - loss: 0.4062 - val_accuracy: 0.8525 - val_loss: 0.3926\n",
      "Epoch 32/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8529 - loss: 0.3935 - val_accuracy: 0.8525 - val_loss: 0.3934\n",
      "Epoch 33/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8512 - loss: 0.3969 - val_accuracy: 0.8534 - val_loss: 0.3898\n",
      "Epoch 34/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8558 - loss: 0.3894 - val_accuracy: 0.8546 - val_loss: 0.3916\n",
      "Epoch 35/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8515 - loss: 0.3885 - val_accuracy: 0.8561 - val_loss: 0.3897\n",
      "Epoch 36/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8560 - loss: 0.3827 - val_accuracy: 0.8553 - val_loss: 0.3880\n",
      "Epoch 37/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8524 - loss: 0.3930 - val_accuracy: 0.8569 - val_loss: 0.3868\n",
      "Epoch 38/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8563 - loss: 0.3840 - val_accuracy: 0.8548 - val_loss: 0.3850\n",
      "Epoch 39/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8600 - loss: 0.3814 - val_accuracy: 0.8569 - val_loss: 0.3842\n",
      "Epoch 40/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8596 - loss: 0.3809 - val_accuracy: 0.8578 - val_loss: 0.3836\n",
      "Epoch 41/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8563 - loss: 0.3829 - val_accuracy: 0.8555 - val_loss: 0.3829\n",
      "Epoch 42/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8613 - loss: 0.3763 - val_accuracy: 0.8580 - val_loss: 0.3821\n",
      "Epoch 43/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8605 - loss: 0.3699 - val_accuracy: 0.8557 - val_loss: 0.3817\n",
      "Epoch 44/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8561 - loss: 0.3770 - val_accuracy: 0.8569 - val_loss: 0.3805\n",
      "Epoch 45/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8635 - loss: 0.3581 - val_accuracy: 0.8582 - val_loss: 0.3798\n",
      "Epoch 46/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8597 - loss: 0.3701 - val_accuracy: 0.8578 - val_loss: 0.3809\n",
      "Epoch 47/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8620 - loss: 0.3750 - val_accuracy: 0.8559 - val_loss: 0.3788\n",
      "Epoch 48/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8654 - loss: 0.3625 - val_accuracy: 0.8567 - val_loss: 0.3809\n",
      "Epoch 49/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8695 - loss: 0.3558 - val_accuracy: 0.8597 - val_loss: 0.3784\n",
      "Epoch 50/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8659 - loss: 0.3603 - val_accuracy: 0.8592 - val_loss: 0.3770\n",
      "Epoch 51/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8675 - loss: 0.3593 - val_accuracy: 0.8584 - val_loss: 0.3757\n",
      "Epoch 52/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8617 - loss: 0.3605 - val_accuracy: 0.8576 - val_loss: 0.3772\n",
      "Epoch 53/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8725 - loss: 0.3525 - val_accuracy: 0.8582 - val_loss: 0.3781\n",
      "Epoch 54/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8687 - loss: 0.3580 - val_accuracy: 0.8584 - val_loss: 0.3764\n",
      "Epoch 55/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8680 - loss: 0.3534 - val_accuracy: 0.8601 - val_loss: 0.3752\n",
      "Epoch 56/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8649 - loss: 0.3505 - val_accuracy: 0.8576 - val_loss: 0.3784\n",
      "Epoch 57/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8686 - loss: 0.3497 - val_accuracy: 0.8590 - val_loss: 0.3755\n",
      "Epoch 58/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8694 - loss: 0.3481 - val_accuracy: 0.8561 - val_loss: 0.3771\n",
      "Epoch 59/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8777 - loss: 0.3388 - val_accuracy: 0.8586 - val_loss: 0.3759\n",
      "Epoch 60/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8736 - loss: 0.3387 - val_accuracy: 0.8584 - val_loss: 0.3749\n",
      "Epoch 61/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8685 - loss: 0.3473 - val_accuracy: 0.8567 - val_loss: 0.3744\n",
      "Epoch 62/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8749 - loss: 0.3336 - val_accuracy: 0.8563 - val_loss: 0.3749\n",
      "Epoch 63/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8753 - loss: 0.3382 - val_accuracy: 0.8580 - val_loss: 0.3745\n",
      "Epoch 64/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8707 - loss: 0.3513 - val_accuracy: 0.8586 - val_loss: 0.3763\n",
      "Epoch 65/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8705 - loss: 0.3446 - val_accuracy: 0.8597 - val_loss: 0.3740\n",
      "Epoch 66/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8749 - loss: 0.3346 - val_accuracy: 0.8588 - val_loss: 0.3733\n",
      "Epoch 67/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8751 - loss: 0.3326 - val_accuracy: 0.8584 - val_loss: 0.3730\n",
      "Epoch 68/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8739 - loss: 0.3359 - val_accuracy: 0.8597 - val_loss: 0.3738\n",
      "Epoch 69/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8758 - loss: 0.3343 - val_accuracy: 0.8613 - val_loss: 0.3724\n",
      "Epoch 70/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8744 - loss: 0.3400 - val_accuracy: 0.8615 - val_loss: 0.3732\n",
      "Epoch 71/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8792 - loss: 0.3286 - val_accuracy: 0.8584 - val_loss: 0.3741\n",
      "Epoch 72/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8780 - loss: 0.3304 - val_accuracy: 0.8615 - val_loss: 0.3717\n",
      "Epoch 73/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8775 - loss: 0.3297 - val_accuracy: 0.8592 - val_loss: 0.3719\n",
      "Epoch 74/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8784 - loss: 0.3343 - val_accuracy: 0.8611 - val_loss: 0.3721\n",
      "Epoch 75/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8801 - loss: 0.3271 - val_accuracy: 0.8601 - val_loss: 0.3720\n",
      "Epoch 76/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8792 - loss: 0.3231 - val_accuracy: 0.8580 - val_loss: 0.3729\n",
      "Epoch 77/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8825 - loss: 0.3199 - val_accuracy: 0.8601 - val_loss: 0.3727\n",
      "Epoch 78/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8816 - loss: 0.3176 - val_accuracy: 0.8590 - val_loss: 0.3723\n",
      "Epoch 79/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8851 - loss: 0.3135 - val_accuracy: 0.8618 - val_loss: 0.3711\n",
      "Epoch 80/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8804 - loss: 0.3264 - val_accuracy: 0.8605 - val_loss: 0.3734\n",
      "Epoch 81/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8780 - loss: 0.3251 - val_accuracy: 0.8595 - val_loss: 0.3749\n",
      "Epoch 82/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8833 - loss: 0.3160 - val_accuracy: 0.8571 - val_loss: 0.3761\n",
      "Epoch 83/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8837 - loss: 0.3165 - val_accuracy: 0.8590 - val_loss: 0.3730\n",
      "Epoch 84/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8820 - loss: 0.3159 - val_accuracy: 0.8595 - val_loss: 0.3732\n",
      "Epoch 85/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8834 - loss: 0.3171 - val_accuracy: 0.8601 - val_loss: 0.3737\n",
      "Epoch 86/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8824 - loss: 0.3088 - val_accuracy: 0.8618 - val_loss: 0.3737\n",
      "Epoch 87/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8831 - loss: 0.3124 - val_accuracy: 0.8613 - val_loss: 0.3730\n",
      "Epoch 88/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8807 - loss: 0.3166 - val_accuracy: 0.8586 - val_loss: 0.3731\n",
      "Epoch 89/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8828 - loss: 0.3119 - val_accuracy: 0.8576 - val_loss: 0.3727\n",
      "Epoch 90/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8860 - loss: 0.3086 - val_accuracy: 0.8613 - val_loss: 0.3730\n",
      "Epoch 91/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8823 - loss: 0.3117 - val_accuracy: 0.8592 - val_loss: 0.3734\n",
      "Epoch 92/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8836 - loss: 0.3076 - val_accuracy: 0.8607 - val_loss: 0.3740\n",
      "Epoch 93/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8838 - loss: 0.3154 - val_accuracy: 0.8613 - val_loss: 0.3734\n",
      "Epoch 94/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8838 - loss: 0.3139 - val_accuracy: 0.8607 - val_loss: 0.3745\n",
      "Epoch 95/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8840 - loss: 0.3152 - val_accuracy: 0.8597 - val_loss: 0.3715\n",
      "Epoch 96/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8850 - loss: 0.3060 - val_accuracy: 0.8590 - val_loss: 0.3755\n",
      "Epoch 97/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8888 - loss: 0.3034 - val_accuracy: 0.8607 - val_loss: 0.3734\n",
      "Epoch 98/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8832 - loss: 0.3080 - val_accuracy: 0.8597 - val_loss: 0.3730\n",
      "Epoch 99/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8842 - loss: 0.3033 - val_accuracy: 0.8605 - val_loss: 0.3735\n",
      "Epoch 100/100\n",
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8897 - loss: 0.2986 - val_accuracy: 0.8620 - val_loss: 0.3708\n",
      "Model saved as ../Models/mlp_model_2.keras\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step\n",
      "\n",
      "Validation Metrics:\n",
      "F1-Score (Validation): 0.8582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93      3211\n",
      "           1       0.75      0.67      0.71       970\n",
      "           2       0.78      0.68      0.73       586\n",
      "\n",
      "    accuracy                           0.86      4767\n",
      "   macro avg       0.81      0.77      0.79      4767\n",
      "weighted avg       0.86      0.86      0.86      4767\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 149\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# Matriz de confusión en validación\u001b[39;00m\n\u001b[1;32m    148\u001b[0m conf_matrix_val \u001b[38;5;241m=\u001b[39m confusion_matrix(y_val, y_val_pred)\n\u001b[0;32m--> 149\u001b[0m disp_val \u001b[38;5;241m=\u001b[39m ConfusionMatrixDisplay(conf_matrix_val, display_labels\u001b[38;5;241m=\u001b[39m\u001b[43mfinal_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_classes\u001b[49m(X_val))\n\u001b[1;32m    150\u001b[0m disp_val\u001b[38;5;241m.\u001b[39mplot(cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m\"\u001b[39m, values_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    151\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfusion Matrix (Validation Set)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Definir columnas numéricas a estandarizar\n",
    "numeric_cols = [\"CAPITAL\", \"CONTEO_PRODUCTOS\", \"Cupo\", \"DiasMejorGestion\", \"DiasUltimaGestion\", \"EDAD\", 'GRUPO', 'Mora_maxima_cliente__Asignacion', 'PgMin', 'SaldoCliente', 'SaldoVencido', 'TotalGestiones', 'TotalGestionesCD', 'TotalGestionesCI', 'TotalGestionesCompromiso', 'TotalGestionesMasivas', 'TotalGestionesNC', 'dias_mora_Asignacion', 'saldo_total']\n",
    "\n",
    "# Separar características y variable objetivo\n",
    "X = df.drop(columns=[\"Cuenta\", \"Estado\"])  # Excluir identificador y objetivo\n",
    "y = df[\"Estado\"]\n",
    "\n",
    "# División en train, val y test (estratificado)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Aplicar StandardScaler solo a las columnas numéricas\n",
    "scaler = StandardScaler()\n",
    "X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "X_val[numeric_cols] = scaler.transform(X_val[numeric_cols])\n",
    "X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "# Guardar el scaler\n",
    "scaler_filename = \"../Models/scaler_2.pkl\"\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "\n",
    "# Definir nombres de archivos\n",
    "model_filename = \"../Models/mlp_model_2.keras\"\n",
    "study_filename = \"../Study/optuna_study_MLP_2.pkl\"\n",
    "\n",
    "# Obtener el número de características después del preprocesamiento\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "# Función objetivo para Optuna\n",
    "def objective(trial):\n",
    "    # Espacio de hiperparámetros\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    units = trial.suggest_int(\"units\", 32, 256)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.05, 0.5)\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
    "    \n",
    "    # Construcción del modelo\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=(input_dim,)))\n",
    "    \n",
    "    for _ in range(n_layers):\n",
    "        model.add(layers.Dense(units, activation=\"relu\"))\n",
    "        model.add(layers.Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(layers.Dense(len(y.unique()), activation=\"softmax\"))  # Salida con clases\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    # Entrenamiento con Early Stopping\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        verbose=0,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "    # Evaluación en validación\n",
    "    y_val_pred = np.argmax(model.predict(X_val), axis=1)\n",
    "    f1 = f1_score(y_val, y_val_pred, average=\"weighted\")\n",
    "\n",
    "    return f1\n",
    "\n",
    "# Intentar cargar el estudio de Optuna si existe\n",
    "if os.path.exists(study_filename):\n",
    "    print(f\"Study found. Loading from {study_filename}...\")\n",
    "    study_mlp = joblib.load(study_filename)\n",
    "else:\n",
    "    print(\"Study not found. Creating a new one...\")\n",
    "    pruner = optuna.pruners.MedianPruner()\n",
    "    study_mlp = optuna.create_study(direction=\"maximize\", pruner=pruner)\n",
    "\n",
    "    # Ejecutar la optimización\n",
    "    start_time = time.time()\n",
    "    study_mlp.optimize(objective, n_trials=50)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Guardar el estudio de Optuna\n",
    "    joblib.dump(study_mlp, study_filename)\n",
    "    print(f\"Study saved as {study_filename}\")\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study_mlp.best_trial\n",
    "    print(\"  Value:\", trial.value)\n",
    "    print(\"  Params:\", trial.params)\n",
    "    print(f\"Optimization time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Obtener los mejores parámetros de la optimización\n",
    "best_params = study_mlp.best_params\n",
    "\n",
    "# Entrenar el modelo final con los mejores parámetros\n",
    "final_model = keras.Sequential()\n",
    "final_model.add(layers.Input(shape=(input_dim,)))\n",
    "\n",
    "for _ in range(best_params[\"n_layers\"]):\n",
    "    final_model.add(layers.Dense(best_params[\"units\"], activation=\"relu\"))\n",
    "    final_model.add(layers.Dropout(best_params[\"dropout_rate\"]))\n",
    "\n",
    "final_model.add(layers.Dense(len(y.unique()), activation=\"softmax\"))\n",
    "\n",
    "final_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=best_params[\"learning_rate\"]),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "final_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "final_model.save(model_filename)\n",
    "print(f\"Model saved as {model_filename}\")\n",
    "\n",
    "# Evaluación en validación\n",
    "y_val_pred = np.argmax(final_model.predict(X_val), axis=1)\n",
    "\n",
    "print(\"\\nValidation Metrics:\")\n",
    "print(f\"F1-Score (Validation): {f1_score(y_val, y_val_pred, average='weighted'):.4f}\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Matriz de confusión en validación\n",
    "conf_matrix_val = confusion_matrix(y_val, y_val_pred)\n",
    "disp_val = ConfusionMatrixDisplay(conf_matrix_val, display_labels=final_model.predict_classes(X_val))\n",
    "disp_val.plot(cmap=\"Blues\", values_format=\"d\")\n",
    "plt.title(\"Confusion Matrix (Validation Set)\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
