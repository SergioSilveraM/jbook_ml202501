Traceback (most recent call last):
  File "/home/ssilvera/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/home/ssilvera/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/nbclient/client.py", line 1319, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssilvera/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/jupyter_core/utils/__init__.py", line 165, in wrapped
    return loop.run_until_complete(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/base_events.py", line 687, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/home/ssilvera/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/nbclient/client.py", line 709, in async_execute
    await self.async_execute_cell(
  File "/home/ssilvera/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/home/ssilvera/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
import os
import joblib
import pandas as pd
import numpy as np
import optuna
import time
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import train_test_split

# Definir columnas numÃ©ricas a estandarizar
numeric_cols = ["CAPITAL", "CONTEO_PRODUCTOS", "Cupo", "DiasMejorGestion", "DiasUltimaGestion", "EDAD", 'GRUPO', 'Mora_maxima_cliente__Asignacion', 'PgMin', 'SaldoCliente', 'SaldoVencido', 'TotalGestiones', 'TotalGestionesCD', 'TotalGestionesCI', 'TotalGestionesCompromiso', 'TotalGestionesMasivas', 'TotalGestionesNC', 'dias_mora_Asignacion', 'saldo_total']

# Separar caracterÃ­sticas y variable objetivo
X = df.drop(columns=["Cuenta", "Estado"])  # Excluir identificador y objetivo
y = df["Estado"]

# DivisiÃ³n en train, val y test (estratificado)
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)

# Aplicar StandardScaler solo a las columnas numÃ©ricas
scaler = StandardScaler()
X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])
X_val[numeric_cols] = scaler.transform(X_val[numeric_cols])
X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])

# Guardar el scaler
scaler_filename = "../Models/scaler_2.pkl"
joblib.dump(scaler, scaler_filename)

# Definir nombres de archivos
model_filename = "../Models/mlp_model_2.keras"
study_filename = "../Study/optuna_study_MLP_2.pkl"

# Obtener el nÃºmero de caracterÃ­sticas despuÃ©s del preprocesamiento
input_dim = X_train.shape[1]

# FunciÃ³n objetivo para Optuna
def objective(trial):
    # Espacio de hiperparÃ¡metros
    n_layers = trial.suggest_int("n_layers", 1, 3)
    units = trial.suggest_int("units", 32, 256)
    dropout_rate = trial.suggest_float("dropout_rate", 0.05, 0.5)
    learning_rate = trial.suggest_loguniform("learning_rate", 1e-5, 1e-1)
    
    # ConstrucciÃ³n del modelo
    model = keras.Sequential()
    model.add(layers.Input(shape=(input_dim,)))
    
    for _ in range(n_layers):
        model.add(layers.Dense(units, activation="relu"))
        model.add(layers.Dropout(dropout_rate))
    
    model.add(layers.Dense(len(y.unique()), activation="softmax"))  # Salida con clases
    
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),
        loss="sparse_categorical_crossentropy",
        metrics=["accuracy"]
    )

    # Entrenamiento con Early Stopping
    early_stopping = keras.callbacks.EarlyStopping(monitor="val_loss", patience=5, restore_best_weights=True)
    
    model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=100,
        batch_size=32,
        verbose=0,
        callbacks=[early_stopping]
    )

    # EvaluaciÃ³n en validaciÃ³n
    y_val_pred = np.argmax(model.predict(X_val), axis=1)
    f1 = f1_score(y_val, y_val_pred, average="weighted")

    return f1

# Intentar cargar el estudio de Optuna si existe
if os.path.exists(study_filename):
    print(f"Study found. Loading from {study_filename}...")
    study_mlp = joblib.load(study_filename)
else:
    print("Study not found. Creating a new one...")
    pruner = optuna.pruners.MedianPruner()
    study_mlp = optuna.create_study(direction="maximize", pruner=pruner)

    # Ejecutar la optimizaciÃ³n
    start_time = time.time()
    study_mlp.optimize(objective, n_trials=50)
    end_time = time.time()

    # Guardar el estudio de Optuna
    joblib.dump(study_mlp, study_filename)
    print(f"Study saved as {study_filename}")

    print("Best trial:")
    trial = study_mlp.best_trial
    print("  Value:", trial.value)
    print("  Params:", trial.params)
    print(f"Optimization time: {end_time - start_time:.2f} seconds")

# Obtener los mejores parÃ¡metros de la optimizaciÃ³n
best_params = study_mlp.best_params

# Entrenar el modelo final con los mejores parÃ¡metros
final_model = keras.Sequential()
final_model.add(layers.Input(shape=(input_dim,)))

for _ in range(best_params["n_layers"]):
    final_model.add(layers.Dense(best_params["units"], activation="relu"))
    final_model.add(layers.Dropout(best_params["dropout_rate"]))

final_model.add(layers.Dense(len(y.unique()), activation="softmax"))

final_model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=best_params["learning_rate"]),
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

final_model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=100,
    batch_size=32,
    verbose=1
)

# Guardar el modelo entrenado
final_model.save(model_filename)
print(f"Model saved as {model_filename}")

# EvaluaciÃ³n en validaciÃ³n
y_val_pred = np.argmax(final_model.predict(X_val), axis=1)

print("\nValidation Metrics:")
print(f"F1-Score (Validation): {f1_score(y_val, y_val_pred, average='weighted'):.4f}")
print(classification_report(y_val, y_val_pred))

# Matriz de confusiÃ³n en validaciÃ³n
conf_matrix_val = confusion_matrix(y_val, y_val_pred)
disp_val = ConfusionMatrixDisplay(conf_matrix_val, display_labels=final_model.predict_classes(X_val))
disp_val.plot(cmap="Blues", values_format="d")
plt.title("Confusion Matrix (Validation Set)")
plt.show()

------------------

----- stderr -----
2025-02-13 14:40:19.613795: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-13 14:40:19.620184: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1739475619.626693 3312141 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1739475619.628614 3312141 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-02-13 14:40:19.636009: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
----- stdout -----
Study found. Loading from ../Study/optuna_study_MLP_2.pkl...
----- stderr -----
I0000 00:00:1739475620.617352 3312141 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22154 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9
I0000 00:00:1739475620.618513 3312141 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22168 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:02:00.0, compute capability: 8.9
----- stdout -----
Epoch 1/100
----- stderr -----
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1739475621.573963 3312310 service.cc:148] XLA service 0x7513bc016fa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1739475621.573975 3312310 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9
I0000 00:00:1739475621.573976 3312310 service.cc:156]   StreamExecutor device (1): NVIDIA GeForce RTX 4090, Compute Capability 8.9
2025-02-13 14:40:21.587192: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
E0000 00:00:1739475621.683412 3312310 cuda_dnn.cc:522] Loaded runtime CuDNN library: 9.1.0 but source was compiled with: 9.3.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.
E0000 00:00:1739475621.736537 3312310 cuda_dnn.cc:522] Loaded runtime CuDNN library: 9.1.0 but source was compiled with: 9.3.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.
2025-02-13 14:40:21.740052: W tensorflow/core/framework/op_kernel.cc:1841] OP_REQUIRES failed at xla_ops.cc:577 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.
2025-02-13 14:40:21.740078: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.
	 [[{{node StatefulPartitionedCall}}]]
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mFailedPreconditionError[0m                   Traceback (most recent call last)
Cell [0;32mIn[3], line 128[0m
[1;32m    120[0m final_model[38;5;241m.[39madd(layers[38;5;241m.[39mDense([38;5;28mlen[39m(y[38;5;241m.[39munique()), activation[38;5;241m=[39m[38;5;124m"[39m[38;5;124msoftmax[39m[38;5;124m"[39m))
[1;32m    122[0m final_model[38;5;241m.[39mcompile(
[1;32m    123[0m     optimizer[38;5;241m=[39mkeras[38;5;241m.[39moptimizers[38;5;241m.[39mAdam(learning_rate[38;5;241m=[39mbest_params[[38;5;124m"[39m[38;5;124mlearning_rate[39m[38;5;124m"[39m]),
[1;32m    124[0m     loss[38;5;241m=[39m[38;5;124m"[39m[38;5;124msparse_categorical_crossentropy[39m[38;5;124m"[39m,
[1;32m    125[0m     metrics[38;5;241m=[39m[[38;5;124m"[39m[38;5;124maccuracy[39m[38;5;124m"[39m]
[1;32m    126[0m )
[0;32m--> 128[0m [43mfinal_model[49m[38;5;241;43m.[39;49m[43mfit[49m[43m([49m
[1;32m    129[0m [43m    [49m[43mX_train[49m[43m,[49m[43m [49m[43my_train[49m[43m,[49m
[1;32m    130[0m [43m    [49m[43mvalidation_data[49m[38;5;241;43m=[39;49m[43m([49m[43mX_val[49m[43m,[49m[43m [49m[43my_val[49m[43m)[49m[43m,[49m
[1;32m    131[0m [43m    [49m[43mepochs[49m[38;5;241;43m=[39;49m[38;5;241;43m100[39;49m[43m,[49m
[1;32m    132[0m [43m    [49m[43mbatch_size[49m[38;5;241;43m=[39;49m[38;5;241;43m32[39;49m[43m,[49m
[1;32m    133[0m [43m    [49m[43mverbose[49m[38;5;241;43m=[39;49m[38;5;241;43m1[39;49m
[1;32m    134[0m [43m)[49m
[1;32m    136[0m [38;5;66;03m# Guardar el modelo entrenado[39;00m
[1;32m    137[0m final_model[38;5;241m.[39msave(model_filename)

File [0;32m~/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122[0m, in [0;36mfilter_traceback.<locals>.error_handler[0;34m(*args, **kwargs)[0m
[1;32m    119[0m     filtered_tb [38;5;241m=[39m _process_traceback_frames(e[38;5;241m.[39m__traceback__)
[1;32m    120[0m     [38;5;66;03m# To get the full stack trace, call:[39;00m
[1;32m    121[0m     [38;5;66;03m# `keras.config.disable_traceback_filtering()`[39;00m
[0;32m--> 122[0m     [38;5;28;01mraise[39;00m e[38;5;241m.[39mwith_traceback(filtered_tb) [38;5;28;01mfrom[39;00m[38;5;250m [39m[38;5;28;01mNone[39;00m
[1;32m    123[0m [38;5;28;01mfinally[39;00m:
[1;32m    124[0m     [38;5;28;01mdel[39;00m filtered_tb

File [0;32m~/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53[0m, in [0;36mquick_execute[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)[0m
[1;32m     51[0m [38;5;28;01mtry[39;00m:
[1;32m     52[0m   ctx[38;5;241m.[39mensure_initialized()
[0;32m---> 53[0m   tensors [38;5;241m=[39m pywrap_tfe[38;5;241m.[39mTFE_Py_Execute(ctx[38;5;241m.[39m_handle, device_name, op_name,
[1;32m     54[0m                                       inputs, attrs, num_outputs)
[1;32m     55[0m [38;5;28;01mexcept[39;00m core[38;5;241m.[39m_NotOkStatusException [38;5;28;01mas[39;00m e:
[1;32m     56[0m   [38;5;28;01mif[39;00m name [38;5;129;01mis[39;00m [38;5;129;01mnot[39;00m [38;5;28;01mNone[39;00m:

[0;31mFailedPreconditionError[0m: Graph execution error:

Detected at node StatefulPartitionedCall defined at (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main

  File "<frozen runpy>", line 88, in _run_code

  File "/home/ssilvera/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/ipykernel_launcher.py", line 18, in <module>

  File "/home/ssilvera/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/traitlets/config/application.py", line 1075, in launch_instance

  File "/home/ssilvera/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/ipykernel/kernelapp.py", line 739, in start

  File "/home/ssilvera/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/tornado/platform/asyncio.py", line 205, in start

  File "/usr/lib/python3.12/asyncio/base_events.py", line 641, in run_forever

  File "/usr/lib/python3.12/asyncio/base_events.py", line 1987, in _run_once

  File "/usr/lib/python3.12/asyncio/events.py", line 88, in _run

  File "/home/ssilvera/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py", line 545, in dispatch_queue

  File "/home/ssilvera/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py", line 534, in process_one

  File "/home/ssilvera/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py", line 437, in dispatch_shell

  File "/home/ssilvera/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py", line 362, in execute_request

  File "/home/ssilvera/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py", line 778, in execute_request

  File "/home/ssilvera/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py", line 449, in do_execute

  File "/home/ssilvera/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py", line 549, in run_cell

  File "/home/ssilvera/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py", line 3075, in run_cell

  File "/home/ssilvera/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py", line 3130, in _run_cell

  File "/home/ssilvera/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/IPython/core/async_helpers.py", line 128, in _pseudo_sync_runner

  File "/home/ssilvera/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py", line 3334, in run_cell_async

  File "/home/ssilvera/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py", line 3517, in run_ast_nodes

  File "/home/ssilvera/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py", line 3577, in run_code

  File "/tmp/ipykernel_3312141/1076475844.py", line 128, in <module>

  File "/home/ssilvera/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler

  File "/home/ssilvera/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py", line 371, in fit

  File "/home/ssilvera/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py", line 219, in function

  File "/home/ssilvera/Escritorio/Proyectos/Modelo_pagos/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py", line 132, in multi_step_on_iterator

DNN library initialization failed. Look at the errors above for more details.
	 [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_1855]

